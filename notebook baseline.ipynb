{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pylab as plt\n",
    "import librosa\n",
    "import librosa.display\n",
    "import pandas as pd\n",
    "import midi\n",
    "import glob\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_midi(fname, instrument_id):\n",
    "    pattern = midi.read_midifile(fname)    \n",
    "    bpm = list(filter(lambda x: isinstance(x, midi.SetTempoEvent), pattern[0]))[0].bpm\n",
    "    tdict = {\n",
    "        midi.NoteOnEvent: 1,\n",
    "        midi.NoteOffEvent: -1\n",
    "    }\n",
    "    events = []\n",
    "    for i in range(1, 5):    \n",
    "        t = np.cumsum([e.tick for e in pattern[i]], dtype=np.int32)                         \n",
    "        events.extend([(t, i - 1, tdict[e.__class__], e.pitch) for (t, e) in zip(t, pattern[i]) if e.__class__ in tdict])\n",
    "    events = list(sorted(events, key=lambda x: (x[0], x[2])))\n",
    "    \n",
    "    chord = [0] * 4\n",
    "    \n",
    "    chords = []    \n",
    "        \n",
    "    for i in range(len(events)):\n",
    "        if (i > 0) and (events[i - 1][0] != events[i][0]):\n",
    "            chords.append((events[i - 1][0], tuple(chord)))            \n",
    "        if events[i][2] == 1:\n",
    "            chord[events[i][1]] = events[i][3]            \n",
    "        else:            \n",
    "            chord[events[i][1]] = 0            \n",
    "    chords.append((events[-1][0], tuple(chord)))\n",
    "    \n",
    "    score = []\n",
    "    for (t, chord) in chords:\n",
    "        if len(score) > 0 and score[-1][-1] == chord[instrument_id]:\n",
    "            continue            \n",
    "        score.append((t, t / pattern.resolution, t * 60000.0 / bpm / pattern.resolution, chord[instrument_id]))\n",
    "        \n",
    "                        \n",
    "            \n",
    "    return pd.DataFrame(score)\n",
    "\n",
    "def wav_features(fname):\n",
    "    sr = 44100\n",
    "    r, _ = librosa.load(fname, sr=sr, offset=0.023)\n",
    "    n_fft, hop_length = 1024, 441\n",
    "    features = np.vstack([\n",
    "        librosa.feature.rmse(r, frame_length=n_fft, hop_length=hop_length),\n",
    "        librosa.feature.spectral_centroid(r, sr=sr, n_fft=n_fft, hop_length=hop_length),\n",
    "        librosa.feature.spectral_bandwidth(r, sr=sr, n_fft=n_fft, hop_length=hop_length),\n",
    "        librosa.feature.mfcc(r, sr=sr, n_mfcc=5, n_fft=n_fft, hop_length=hop_length)        \n",
    "    ]).T\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "instruments = {\n",
    "    'violin': 0,\n",
    "    'clarinet': 1,\n",
    "    'saxphone': 2,\n",
    "    'bassoon': 3,\n",
    "}\n",
    "\n",
    "instrument = 'bassoon'\n",
    "\n",
    "dirs = list(sorted(glob.glob('./data/Bach10/??-*')))\n",
    "mid_files = list(map(lambda x: '%s/%s.mid' % (x, x.split('/')[-1]), dirs))\n",
    "wav_files = list(map(lambda x: '%s/%s-%s.wav' % (x, x.split('/')[-1], instrument), dirs))\n",
    "asl_files = list(map(lambda x: '%s/%s.asl' % (x, x.split('/')[-1]), dirs))\n",
    "\n",
    "alignments = []\n",
    "features = []\n",
    "scores = []\n",
    "for i in range(10):        \n",
    "    alignments.append(pd.read_csv(asl_files[i], sep='\\t', header=None, index_col=None))     \n",
    "    scores.append(parse_midi(mid_files[i], instruments[instrument]))\n",
    "    features.append(wav_features(wav_files[i]))\n",
    "    features[-1] = features[-1][:alignments[-1].shape[0]]\n",
    "    ids = alignments[-1][2] > 0.0\n",
    "    alignments[-1] = alignments[-1][ids]\n",
    "    alignments[-1][2] -= alignments[-1][2].min() - np.modf(alignments[-1][2].min())[0]\n",
    "    features[-1] = features[-1][ids]\n",
    "    alignments[-1] = alignments[-1].iloc[::4]\n",
    "    features[-1] = features[-1][::4]\n",
    "    \n",
    "    scores[-1][1] -= scores[-1][1][0]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grountruth_matrix(alignment, s):\n",
    "    b = alignment[2].copy()\n",
    "    mx = np.ceil(np.max(alignment[2]) * 2) / 2    \n",
    "    #s = np.arange(0.0, mx, 0.5)        \n",
    "    #print(s, np.arange(0.0, mx, 0.5))\n",
    "    #Y = ((b[:, None] >= s[None, :]) & (b[:, None] < s[None, :] + 0.5)).astype(np.int32)\n",
    "    Y = ((b[:, None] >= s[None, :-1]) & (b[:, None] < s[None, 1:])).astype(np.int32)\n",
    "    return Y\n",
    "\n",
    "def prepare(scores, alignments):\n",
    "    S = set(sum(map(lambda x: x[3].tolist(), scores), []))\n",
    "    K = len(S)    \n",
    "    id_to_key = {i: k for i, k in enumerate(S)}\n",
    "    key_to_id = {k: i for i, k in enumerate(S)}\n",
    "    \n",
    "    GTs = []\n",
    "    Bs = []\n",
    "    \n",
    "    SYs = []\n",
    "    \n",
    "    for k in range(len(scores)):        \n",
    "        GT = grountruth_matrix(alignments[k], scores[k][1])\n",
    "        B = np.array([key_to_id[v] for v in scores[k][3][:-1]], dtype=np.int32)\n",
    "        #j = 0\n",
    "        #for i in range(B.shape[0]):\n",
    "        #    while (2 * scores[k][1][j + 1] <= i):\n",
    "        #        j += 1            \n",
    "        #    B[i] = key_to_id[scores[k][3][j]]\n",
    "        GTs.append(GT)\n",
    "        Bs.append(B)\n",
    "        \n",
    "        SY = np.zeros(alignments[k].shape[0], dtype=np.int32)\n",
    "        j = 0\n",
    "        for i in range(alignments[k].shape[0]):\n",
    "            while (scores[k][1][j + 1] <= alignments[k].iloc[i, 2]):\n",
    "                j += 1            \n",
    "            SY[i] = key_to_id[scores[k][3][j]]\n",
    "        SYs.append(SY)\n",
    "        \n",
    "    return GTs, Bs, SYs, K\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "GTs, Bs, SYs, K = prepare(scores, alignments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Логистическая регрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pavel/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:718: UserWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\"lbfgs failed to converge. Increase the number \"\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    5.9s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10000.0, class_weight=None, dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=1000,\n",
       "          multi_class='multinomial', n_jobs=1, penalty='l2',\n",
       "          random_state=None, solver='lbfgs', tol=0.0001, verbose=True,\n",
       "          warm_start=False)"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "X_train = np.vstack(features[5:])\n",
    "Y_train = np.concatenate(SYs[5:])\n",
    "\n",
    "\n",
    "X_test = np.vstack(features[:5])\n",
    "Y_test = np.concatenate(SYs[:5])\n",
    "\n",
    "m, s = np.mean(X_train, axis=0, keepdims=True), np.std(X_train, axis=0, keepdims=True)\n",
    "X_train = (X_train - m) / s\n",
    "X_test = (X_test - m) / s\n",
    "\n",
    "clf = sklearn.linear_model.LogisticRegression(\n",
    "    C=1e4, solver='lbfgs', multi_class='multinomial', verbose=True, max_iter=1000)\n",
    "clf.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.41475631784\n",
      "0.633375796178\n",
      "---\n",
      "-4.04623289723\n",
      "0.476541390322\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(clf.predict_log_proba(X_train)[np.arange(X_train.shape[0]), Y_train]))\n",
    "print(np.mean(clf.predict(X_train) == Y_train))\n",
    "print('---')\n",
    "print(np.mean(clf.predict_log_proba(X_test)[np.arange(X_test.shape[0]), Y_test]))\n",
    "print(np.mean(clf.predict(X_test) == Y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DTW(theta):\n",
    "    D = np.zeros((theta.shape[0] + 1, theta.shape[1] + 1))\n",
    "    D[0, 1:] = 1e20\n",
    "    D[1:, 0] = 1e20 \n",
    "    Q = np.zeros((theta.shape[0] + 1, theta.shape[1] + 1, 2), dtype=np.int32)    \n",
    "    for i in range(1, theta.shape[0] + 1):\n",
    "        tmp = np.hstack([D[i - 1, 1:][:, None], D[i - 1, :-1][:, None]]) + theta[i - 1, :][:, None]\n",
    "        Q[i - 1, np.arange(theta.shape[1]), np.argmin(tmp, axis=1)] = 1                 \n",
    "        D[i, 1:] = np.sum(tmp * Q[i - 1, :-1], axis=1)        \n",
    "        \n",
    "    Y = np.zeros((theta.shape[0] + 1, theta.shape[1] + 1), dtype=np.int32)\n",
    "    Y[-1, -1] = 1\n",
    "    Q[-1, -1] = [0, 1]\n",
    "    j = theta.shape[1] - 1    \n",
    "    for i in range(theta.shape[0] - 1, -1, -1):\n",
    "        Y[i, :-1] = np.sum(\n",
    "            np.hstack([Y[i + 1, :-1][:, None], Y[i + 1, 1:][:, None]]) * \n",
    "            np.hstack([Q[i + 1, :-1, 0][:, None], Q[i + 1, 1:, 1][:, None]]), axis=1)\n",
    "    \n",
    "    return D[:-1, :-1], Y[:-1, :-1]\n",
    "\n",
    "def MAD(Y, GT):\n",
    "    return np.sum(np.cumsum(Y - GT, axis=1) ** 2) / GT.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.28618968386\n",
      "0.180512820513\n",
      "11.1766612642\n",
      "0.205882352941\n",
      "0.289044289044\n",
      "Average MAD 1.89191844756\n"
     ]
    }
   ],
   "source": [
    "res = 0\n",
    "for i in range(5):\n",
    "    theta = -np.log(\n",
    "        clf.predict_proba((features[i] - m) / s)[np.arange(features[i].shape[0])[:, None], Bs[i][None, :]]\n",
    "        + 0.1)\n",
    "    v, Y = DTW(theta)\n",
    "    print(MAD(Y, GTs[i]))\n",
    "    res += MAD(Y, GTs[i]) * Y.shape[0]\n",
    "\n",
    "res /= Y_test.shape[0]\n",
    "print('Average MAD', res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
       "            oob_score=False, random_state=42, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "X_train = np.vstack(features[5:])\n",
    "Y_train = np.concatenate(SYs[5:])\n",
    "\n",
    "\n",
    "X_test = np.vstack(features[:5])\n",
    "Y_test = np.concatenate(SYs[:5])\n",
    "\n",
    "m, s = np.mean(X_train, axis=0, keepdims=True), np.std(X_train, axis=0, keepdims=True)\n",
    "X_train = (X_train - m) / s\n",
    "X_test = (X_test - m) / s\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.827961783439\n",
      "1.0\n",
      "---\n",
      "0.389707688529\n",
      "0.543109801032\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(clf.predict_proba(X_train)[np.arange(X_train.shape[0]), Y_train]))\n",
    "print(np.mean(clf.predict(X_train) == Y_train))\n",
    "print('---')\n",
    "print(np.mean(clf.predict_proba(X_test)[np.arange(X_test.shape[0]), Y_test]))\n",
    "print(np.mean(clf.predict(X_test) == Y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.237936772047\n",
      "0.180512820513\n",
      "2.7471636953\n",
      "0.16862745098\n",
      "0.132867132867\n",
      "Average MAD 0.564971751412\n"
     ]
    }
   ],
   "source": [
    "res = 0\n",
    "for i in range(5):\n",
    "    theta = -np.log(\n",
    "        clf.predict_proba((features[i] - m) / s)[np.arange(features[i].shape[0])[:, None], Bs[i][None, :]]\n",
    "        + 0.1)\n",
    "    v, Y = DTW(theta)\n",
    "    print(MAD(Y, GTs[i]))\n",
    "    res += MAD(Y, GTs[i]) * Y.shape[0]\n",
    "    \n",
    "res /= Y_test.shape[0]\n",
    "print('Average MAD', res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
